# 하둡 1일차

책 29P ~

#1,2장은 정독 해보는 것이 좋음.



### 하둡의 특징



- 대용량 데이터 처리 능력 : 하둡은 하둡 클러스터를 이용해서 기가~테라 바이트의 하둡 파일을 백만 개 이상 저장할 수 있으며, 수 페타바이트 ~ 엑사바이트 데이터같이 매우 큰 데이터를 다룰 수 있도록 설계 되었다.

  

- 장애 허용 : 하둡은 하드웨어가 장애가 발생할 수 있다는 것을 전제로 모든 것이 설계 되었다. 그러므로 다수의 서버를 사용해 일을 진행하다가 스토리지나 서버 자체에 문제가 발생한다고 하더라도 영향을 받지 않고 작업을 이어 갈 수 있다. ( 기본적으로 데이터를 3벌 씩 복사해서 보관한다.)

  

- 높은 장애 대응력 : ( 얀이나 HDFS는 1개 혹은 그 이상의 디스크가 작동하지 않거나 멈추어도 방해를 받지 않고 작업을 계속 수행할 수 있다.)

  

- 데이터의 스트리밍 엑세스 :  전통적인 DB는 배치 프로세싱 보다는 데이터에 빠르게 엑세스 하는 것에 중점을 두었지만, 하둡은 수백 개의 웹 페이지에 목차를 달거나 데이터 세트에 스트리밍 엑세스 하는 것 과 같은 배치 프로세싱을 위해 고안 되었다. 

  

- 간단한 데이터 일관성 모델 : 하둡은 WORM 모델(Write - once - read - many access model) 을 사용하여 단 하나의 작업자만이 쓸 수 있기 때문에 데이터 변경 시에 발생할 수 있는 일관성 문제가 발생하지 않는다.





하둡은 데이터를 수정하는 것 보다 삭제하고 데이터를 새로 넣는 것이 비용이 적게 든다.



데이터를 이동하는 방식에서 로직을 이동하는 방식으로 바뀜.



청크(Chunk) : 매우 큰 파일을 클러스트에 분산하여 청크 단위로 쪼개서 분산 저장한다는 의미.



### 하둡 관리자의 역할



- 시스템 설치와 업그레이드

  - 하둡은 수 많은 제품이 사용되며 관리자는 이런 많은 제품들을 설치하고 환경설정을 할 책임이 있다.

- 개발자 지원

  - 관리자는 데이터를 다루는 많은 개발자와 데이터 분석가를 위해 하둡으로 작업할 수 있도록 ID를 제공하고, 그들의 HDFS 디렉토리들을 위해 할당된 충분한 저장 공간이 있는지 확인해야 한다.

- 성능 튜닝(최적화)

  - 하둡 관리자의 핵심 임무. 
  - 메모리나 CPU 동작을 포함한 서버 레벨의 실행 문제를 해결하는 데 능숙해야 하며, 
  - 클러스터에서 발생하는 네트워크 관련 문제를 찾아낼 수 있어야 한다.
  - 다양한 시스템 매개변수에 적절한 값을 설정해야 한다.

- 모니터링과 트러블 슈팅

  - Nagios나 Ganglia와 같은 툴을 이용해 클러스터 전체를 모니터링하고 관리할 수 있다.
  - 이 툴들은 운영체제, 스토리지, 네트워크를 담당한다.

- 백업과 복구

  - 하둡에는 보통 DB들과 달리 전체 DB백업이라는 개념이 없다.

      -> 하나의 데이터 베이스 라는 것이 없기 때문.

  - but 어떤 데이터들이 매우 중요한 것이라면, 안전하게 다른 클러스터에 복사해 둘 수는 있다.

  - 어떤 경우든 서버나 서버 전체적인 랙에 문제가 생긴다고 해도 데이터에는 문제가 생기지 않는다. (하둡 데이터들은 HDFS 파일로 저장되며 크기가 매우 크기 때문에 이를 백업하는 것은 실행 가능하지도 않고 현실적인 아이디어도 아니다.)





### 데이터 호수

- 데이터 호수란 정형, 비정형 등에 관계 없이 조직의 모든 데이터를 중심부에 저장하도록 하는 것을 의미한다.



- 이때 하둡은 조직의 시스템으로 들어오는 데이터의 흐름에 랜딩 존을 제공함으로써, 데이터 호수의 핵심에 있다.

  

- 장기간 데이터를 보유하는 데 최적의 장소이며, 강력한 ETL(추출,변형,로드) 플랫폼으로서 역할을 수행한다.



- 비용적인 측면에서도 기존 데이터 웨어하우스에 비해 하둡 클러스터에 저장하는 것이 훨씬 비용이 적게 든다.





###  Hadoop 모듈



- ##### Hadoop Common
  - 하둡 환경에서 나머지의 모듈들을 지원하는 기본 유틸리티들을로 다음과 같은 요소들을 포함한다.

    - 운영 시스템 인증이나 파일 시스템과 같은 하둡 클러스터를 위한 필수 서비스 
    - 클러스터 시작 스크립트들이나 그 스크립트들을 위해 필요한 자바 파일
    - 문서
    - 하둡 프레임워크의 소스 코드

    

- #####  HDFS

  - Hadoop Distributed File System

  - 어플리케이션 데이터에 고성능 접근을 지원하는 분산 파일 시스템

  - 데이터에 접속해 높은 처리량을 보여주는 파일 시스템

    ##### 

- ##### HBase

  - HDFS를 스토리지에 사용하는 분산 칼럼 지향의 데이터베이스

    

- #####  Hadoop YARN

  - 작업 스케쥴링과 클러스터 리소스 관리를 위한 프레임워크

  - (하둡의 운영체제?, 하둡 클러스터 리소스 관리)

    

    

- #####  Hadoop MapReduce

  - 대용량 데이터(크기가 큰 데이터 세트)의 병렬처리를 위한 얀 기반 시스템





###  Hadoop 파일 시스템의 장/단점



- ##### 특징 및 장점

  - 선형적인 확장성 제공
  - 글로벌 네임스페이스 제공 (네임 스페이스만 알면 접근 가능하도록 제공을 해준다.)
  - 비용절감
  - 데이터분석 처리에 활용



- #####  일반적인 파일 시스템과 다른 특징과 제약사항

  - 응용프로그램 기반의 파일 시스템
  - 불변 파일만 저장
  - NameSpace 관리를 NameNode 메모리에 저장 (마스터 노드인 네임 노드에서만 네임스페이스를 제공)
  - 전체 처리 용량증가
  - NameNode 이중화 문제
  - Namenode(master)가 죽으면?





###  Hadoop 설계 목표



- ##### 장애복구

  - 복제 데이터 저장
  - 주기적인 상태 체크

  

- #####  스트리밍 방식의 데이터 접근

  - 높은 데이터 처리량에 중점을 두고 있음

  

- ##### 대용량 데이터 저장

  - 하나의 파일이 테라바이트 이상 저장 가능
  - 하나의 인스턴스에서 수백만 개 이상의 파일 지원

  

- #####  데이터 **무결성**

  - 읽기 전용
  - 파일 이동, 삭제, 복사 인터페이스 제공



### 하둡의 구조



![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190813/images/arc.PNG>)







###  HDFS(Hadoop Distributed File System)



- 파일의 분산 저장이 목적

- Namenodes와 Datanodes로 구성
  - Master Namenode
  - Secondary Namenode
  - Datanode

-  저렴한 컴퓨터로 대 용량 데이터를 저장할 수 있는 시스템
  - 네트워크 Raid와 같이 연결된 것 처럼 사용하는 하드디스크
  - Scale Out

-  Block(Chunk) 단위로 파일관리 (저장/복제/삭제)
  - Default Size는 64M

-  복제기능을 통해 안전성/신뢰성을 보장

- 1대의 Master서버에 4000+이상의 Datanodes를 운영할 수 있음.

- API지원
  - 하둡 코어는 Python, Java, C/C++





### 하둡의 패러다임의 전환



***로직이*** ***데이터에 접근하지*** ***말고***

***데이터가 있는 곳에*** ***로직을*** ***옮겨라******!***





### 왜 대용량에 Apache Hadoop이 적합한가?



- 애플리케이션/트랜잭션 로그 정보는 매우 크다.
  - 대용량 파일을 저장할 수 있는 분산 파일 시스템을 제공한다.

- I/O 집중적이면서 CPU도 많이 사용한다.
  - 멀티 노드로 부하를 분산시켜 처리한다.

- 데이터베이스는 하드웨어 추가 시 성능 향상이 linear하지 않다.
  - 장비를 증가시킬 수록 성능이 linear에 가깝게 향상된다.

- 데이터베이스는 소프트웨어와 하드웨어가 비싸다.
  - Apache Hadoop은 무료이다.
  - Intel Core 머신과 리눅스는 싸다.





### 빅데이터 라이프사이클



전체적인 빅데이터 시스템 구성을 위해서는 라이프사이클에 대한 이해가 필수.

라이프사이클별 관련 기술을 검토하여 오픈소스 S/W 도입, 상용솔루션 도입, 개발(SI)로 구분해야 함





![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190813/images/life.PNG>)


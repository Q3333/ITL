# 하둡 2일차

## 1일차 복습



### 빅데이터 6V



- 크기(Volume) : 방대한 양의 데이터(테라, 페타바이트 이상의 크기)
- 다양성(Varity) : 정형(DBMS, 전문 등) + 비정형(SNS, 동영상, 사진, 음성, 텍스트 등)

- 속도(Velocity) : 실시간으로 생산되며, 빠른 속도로 데이터를 처리/분석

- 진실성(Veracity) : 주요 의사결정을 위해 데이터 품질과 신뢰성 확보

- 시각화(Visualization) : 복잡한 대규모 데이터를 시각적으로 표현

- 가치(Value) : 비즈니스 효익을 실현하기 위해 궁극적인 가치를 창출



### Hadoop? 

- 오픈 소스 분산 병렬 (파일 시스템) 프레임 워크

- HDFS(하둡파일시스템), MapReduce, Yarn, Core, 그 외 여러 API 



### 클러스터 

- Master - Slave 구조 
- NameNode (HDFS의 namespace, meta 정보)
- DataNode( 기본 설정 64MB, 128MB 데이터 블럭이 분산되어 저장)

- 각각의 데이터는 3개의 Data 블럭을 복제하여 저장 - 장애 허용,  대응력 높음





파일 저장 유형?

- File System - batch, 스트림 (Sequential)

   -> HDFS, GPS, Object

-  Record(Document) 구조로 저장 - NoSQL

  

  




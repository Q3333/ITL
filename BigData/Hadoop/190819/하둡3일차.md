# 하둡 3일차





### 항공 데이터 관련 빅데이터 처리 연습

 •http://stat-computing.org/dataexpo/2009/the-data.html

•미국 항공편 운항 통계 데이터

•1987년부터 2008년까지 미국 내 모든 상업 항공편에 대한 항공편 도착과 출발 세부 사항에 대한 정보를 제공

•csv 파일, 총 29개 컬럼으로 구성, 컬럼 정보는 콤마(,)를 기준으로 구분

•총 파일 크기 11GB(총 압축 크기 1.6GB)

•분석용 데이터 업로드 : hadoop fs -put   운항 통계 데이터파일  /airline 



#### 폴더생성

root 계정 -

hadoop fs -mkdir /output/airline



#### 라이브 패널 2개가 아닐시

vi /etc/hosts 수정

vi /etc/sysconfig/iptables 수정

systemctl stop iptables

systemctl start iptables





## 출발지연 갯수 구하기



##### 	코드 (자바, 이클립스)

1. 리듀서(Reducer)

```java
package lab.hadoop.airline;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class DelayCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
	
	private IntWritable result = new IntWritable();
	//
	public void reduce(Text key, Iterable<IntWritable> values, Context context)
			throws IOException, InterruptedException {
		int sum = 0;
		for (IntWritable value : values )
			sum += value.get();
		result.set(sum);
		context.write(key,result);
	}
	
}

```



2. 메인



```java
package lab.hadoop.airline;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;


public class DepartureDelayCount {
	
public static void main(String[] args) throws Exception {
Configuration conf = new Configuration();

if(args.length !=2) {
	System.out.println("Usage: DepartureDelay <input> <output>");
	System.exit(2);
}

Job job = new Job(conf, "DepartureDelayCount");

FileSystem hdfs = FileSystem.get(conf);//파일시스템 객체를 생성

Path path = new Path(args[1]);
if(hdfs.exists(path)) {//만일 출력 패스가 존재하면
hdfs.delete(path, true);//출력 패스 삭제, 디렉토리이므로 true
 }



FileInputFormat.addInputPath(job, new Path(args[0]));//입력 패스 지정
FileOutputFormat.setOutputPath(job, new Path(args[1]));//출력 패스 지정

job.setJarByClass(DepartureDelayCount.class);//메인 클래스 지정
job.setMapperClass(DepartureDelayCountMapper.class);//메퍼 클래스 지정
job.setReducerClass(DelayCountReducer.class);//리듀서 클래스 지정

job.setInputFormatClass(TextInputFormat.class);//입력 포맷지정
job.setOutputFormatClass(TextOutputFormat.class);//출력 포맷 지정

job.setOutputKeyClass(Text.class);//출력 키의 타입(단어는 텍스트)
job.setOutputValueClass(IntWritable.class);//출력 값의 타입(갯수는 정수)


job.waitForCompletion(true);//작업 실행 종료때까지 기다립니다.
}
 }

```





3. 맵퍼 (Mapper)



```java
package lab.hadoop.airline;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class DepartureDelayCountMapper extends Mapper<LongWritable, Text, Text, IntWritable>{
	// map 출력값

	private final static IntWritable outputValue = new IntWritable(1);

// map 출력키

private Text outputKey = new Text();



public void map(LongWritable key, Text value, Context context)  throws IOException, InterruptedException {
    if (key.get() > 0) {
	// 콤마 구분자 분리
	String[] colums = value.toString().split(",");
	if (colums != null && colums.length > 0) {
	    try {
		// 출력키 설정
		outputKey.set(colums[0] + "," + colums[1]);
		if (!colums[15].equals("NA")) {
			int depDelayTime = Integer.parseInt(colums[15]);
			if (depDelayTime > 0) {
				// 출력 데이터 생성
				context.write(outputKey, outputValue);
				}
			}
	         } catch (Exception e) {
		e.printStackTrace();
		}
	}
   }
}
}

```





※ colums[15]는 출발지연시간



출력 결과



![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190819/images/air1.PNG>)





### 도착 지연 갯수 구하기





1. 매퍼

```java
package lab.hadoop.delaycount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class DelayCountMapper extends Mapper<LongWritable, Text, Text, IntWritable>{

	//
	private String workType;
	//
	private final static IntWritable outputValue = new IntWritable(1);
	//
	private Text outputKey = new Text();
	
	@Override
	public void setup(Context context) throws IOException, InterruptedException {
		workType = context.getConfiguration().get("workType");
	}
	
	public void map(LongWritable key, Text value, Context context)
		throws IOException, InterruptedException {
		
		if (key.get() > 0 ) {
			//콤마 구분자 처리
			String [] colums = value.toString().split(",");
			if(colums != null && colums.length > 0) {
				try {
					//출발 지연 데이터 출력
					if(workType.equals("departure")) {
						if(!colums[15].equals("NA")) {
							int depDelayTime = Integer.parseInt(colums[15]);
							if(depDelayTime > 0) {
								//출력키 설정
								outputKey.set(colums[0] + "," + colums[1]);
								//출력 데이터 생성
								context.write(outputKey, outputValue);
							}
						}
						//도착 지연 데이터 출력
					}else if(workType.equals("arrival")) {
						if(!colums[15].equals("NA")) {
							int depDelayTime = Integer.parseInt(colums[14]);
							if(depDelayTime > 0) {
								//출력키 설정
								outputKey.set(colums[0] + "," + colums[1]);
								//출력 데이터 생성
								context.write(outputKey, outputValue);
							}
						}	
						
					}
				} catch (Exception e) {
					e.printStackTrace();
				}
			}
		
	}
}
	}


```





2. 리듀서



```java
package lab.hadoop.delaycount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class DelayCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
	
	private IntWritable result = new IntWritable();
	//
	public void reduce(Text key, Iterable<IntWritable> values, Context context)
			throws IOException, InterruptedException {
		int sum = 0;
		for (IntWritable value : values )
			sum += value.get();
		result.set(sum);
		context.write(key,result);
	}
	
}

```





3. 메인 (드라이버)



```java
package lab.hadoop.delaycount;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;



public class DelayCount extends Configured implements Tool {

	public int run(String[] args) throws Exception {
		String[] otherArgs = new GenericOptionsParser(getConf(), args)
				.getRemainingArgs();
		
		//
		if(otherArgs.length != 2) {
			System.err.println("Usage: DelayCount <in> <out>");
			System.exit(2);
		}
		//
		Job job = new Job(getConf(), "DelayCount");
		
		
		//
		FileSystem hdfs = FileSystem.get(getConf());
		
		Path path = new Path(args[1]);
		if (hdfs.exists(path)) {
			hdfs.delete(path,true);
		}
		
		FileInputFormat.addInputPath(job, new Path(otherArgs[0]));//입력 패스 지정
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));//출력 패스 지정
		
		job.setJarByClass(DelayCount.class);//메인 클래스 지정
		job.setMapperClass(DelayCountMapper.class);//메퍼 클래스 지정
		job.setReducerClass(DelayCountReducer.class);//리듀서 클래스 지정
		
		job.setInputFormatClass(TextInputFormat.class);//입력 포맷지정
		job.setOutputFormatClass(TextOutputFormat.class);//출력 포맷 지정
		
		job.setOutputKeyClass(Text.class);//출력 키의 타입(단어는 텍스트)
		job.setOutputValueClass(IntWritable.class);//출력 값의 타입(갯수는 정수)


		job.waitForCompletion(true);//작업 실행 종료때까지 기다립니다.
		return 0;
	}
	
	public static void main(String[] args) throws Exception {
		int res = ToolRunner.run(new Configuration(), new DelayCount(), args);
		System.out.println("## RESULT:" + res);

	}

}

```





출력 화면 :



![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190819/images/delay1.PNG>)









3. 그룹 키를 활용한 지연 횟수 카운팅



1. 매퍼

   ```java
   package lab.hadoop.sort;
   
   import java.io.IOException;
   
   public class DelayCountMapperWithDateKey extends 
   Mapper<LongWritable, Text, DateKey, IntWritable>{
   	
   	// map 출력값
   	private final static IntWritable outputValue = new IntWritable(1);
   
   	
   // map 출력키
   private DateKey outputKey = new DateKey();
   
   
   
   public void map(LongWritable key, Text value, Context context)  
   		throws IOException, InterruptedException {
   	
       if (key.get() > 0) {
   	// 콤마 구분자 분리
   	String[] colums = value.toString().split(",");
   	if (colums != null && colums.length > 0) {
   	    try {
   	    	//출발 지연 데이터 출력
   		if (!colums[15].equals("NA")) {
   			int depDelayTime = Integer.parseInt(colums[15]);
   			if (depDelayTime > 0) {
   				
   				//출력 키 설정 
   				outputKey.setYear("D,"+colums[0]);
   				outputKey.setMonth(new Integer(colums[1]));
   				
   				
   				// 출력 데이터 생성
   				context.write(outputKey, outputValue);
   				}else if (depDelayTime == 0) {
   					context.getCounter(
   							DelayCounters.scheduled_departure)
   					.increment(1);
   			
   				}else if(depDelayTime < 0) {
   					context.getCounter(
   							DelayCounters.early_departure)
   					.increment(1);
   			}
   		}else {
   			context.getCounter(
   			DelayCounters.not_available_departure)
   			.increment(1);
   		}
   		
   		// 도착 지연 데이터 출력
   		if (!colums[14].equals("NA")) {
   			int arrDelayTime = Integer.parseInt(colums[14]);
   			if (arrDelayTime > 0) {
   				
   				//출력 키 설정 
   				outputKey.setYear("A,"+colums[0]);
   				outputKey.setMonth(new Integer(colums[1]));
   				
   				
   				// 출력 데이터 생성
   				context.write(outputKey, outputValue);
   				}else if (arrDelayTime == 0) {
   					context.getCounter(
   							DelayCounters.scheduled_arrival)
   					.increment(1);
   			
   				}else if(arrDelayTime < 0) {
   					context.getCounter(
   							DelayCounters.early_arrival)
   					.increment(1);
   			}
   		}else {
   			context.getCounter(
   			DelayCounters.not_available_arrival)
   			.increment(1);
   		}
   		
   	         } catch (Exception e) {
   		e.printStackTrace();
   		}
   	}
      }
   }
   }
   
   ```

   



2. 리듀서

   ```java
   package lab.hadoop.sort;
   
   import java.io.IOException;
   
   import org.apache.hadoop.io.IntWritable;
   import org.apache.hadoop.io.Text;
   import org.apache.hadoop.mapreduce.Reducer;
   import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;
   
   public class DelayCountReducerWithDateKey extends 
   Reducer<DateKey, IntWritable, DateKey, IntWritable> {
   	
   	private MultipleOutputs<DateKey, IntWritable> mos;
   	
   	//reduce 출력키
   	private DateKey outputKey = new DateKey();
   	// reduce 출력값
   	private IntWritable result = new IntWritable();
   	
   	
   	
   	@Override
   	protected void setup(Context context) 
   			throws IOException, InterruptedException {
   			mos = new MultipleOutputs<DateKey, IntWritable>(context);
   	}
   
   
   
   	public void reduce(DateKey key, Iterable<IntWritable> values, Context context)
   			throws IOException, InterruptedException {
   		// 콤마 구분자 분리
   		String[] colums = key.getYear().split(",");
   		
   		int sum = 0;
   		Integer bMonth = key.getMonth();
   		
   		if(colums[0].equals("D")) {
   			for (IntWritable value : values) {
   				if (bMonth != key.getMonth()) {
   					result.set(sum);
   					outputKey.setYear(key.getYear().substring(2));
   					outputKey.setMonth(bMonth);
   					mos.write("departure", outputKey, result);
   					sum =0;
   				}
   				sum+= value.get();
   				bMonth = key.getMonth();
   			}
   			if (key.getMonth() == bMonth) {
   				outputKey.setYear(key.getYear().substring(2));
   				outputKey.setMonth(key.getMonth());
   				result.set(sum);
   				mos.write("departure", outputKey, result);
   			}
   		}else {
   			for (IntWritable value : values) {
   				if (bMonth != key.getMonth()) {
   					result.set(sum);
   					outputKey.setYear(key.getYear().substring(2));
   					outputKey.setMonth(bMonth);
   					mos.write("arrival", outputKey, result);
   					sum =0;
   				}
   				sum+= value.get();
   				bMonth = key.getMonth();
   
   			}
   			if (key.getMonth() == bMonth) {
   				outputKey.setYear(key.getYear().substring(2));
   				outputKey.setMonth(key.getMonth());
   				result.set(sum);
   				mos.write("arrival", outputKey, result);
   			}
   		}	
   	}
   
   
   
   	@Override
   	protected void cleanup(Context context)
   			throws IOException, InterruptedException {
   		mos.close();
   	}
   	
   }
   
   ```





3. DateKey

```java
package lab.hadoop.sort;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.io.WritableUtils;

public class DateKey implements WritableComparable<DateKey>{

	private String year;
	private Integer month;
	
	public DateKey() {
		
	}
	
	public DateKey(String year, Integer date) {
		this.year = year;
		this.month = date;
	}

	
	public String getYear() {
		return year;
	}

	public void setYear(String year) {
		this.year = year;
	}

	public Integer getMonth() {
		return month;
	}

	public void setMonth(Integer month) {
		this.month = month;
	}

	@Override
	public String toString() {
		return (new StringBuilder()).append(year).append(",").append(month).toString();
	}

	@Override
	public void readFields(DataInput in) throws IOException {
		year = WritableUtils.readString(in);
		month = in.readInt();
		}

	@Override
	public void write(DataOutput out) throws IOException {
		WritableUtils.writeString(out, year);
		out.writeInt(month);
	}

	@Override
	public int compareTo(DateKey key) {
		int result = year.compareTo(key.year);
		if (0 == result) {
			result = month.compareTo(key.month);
		}
		return result;
	}
	
	
	

}

```





4. DateKeyComparator



```java
package lab.hadoop.sort;

import org.apache.hadoop.io.WritableComparable;

public class DateKeyComparator extends WritableComparator {
	protected DateKeyComparator() {
		super(DateKey.class,true);
	}


	
	@SuppressWarnings("rawtypes")
	@Override
	public int compare(WritableComparable w1, WritableComparable w2) {
		//복합 키 클래스 캐스팅
	DateKey k1 = (DateKey) w1;
	DateKey k2 = (DateKey) w2;
	
	//연도 비교
	int cmp = k1.getYear().compareTo(k2.getYear());
	if (cmp != 0) {
		return cmp;
	}
	
	//월 비교 
	return k1.getMonth() == k2.getMonth() ? 0 : (k1.getMonth() < 
			k2.getMonth() ? -1 : 1);
		
	}
	
}

```







5. DelayCounters



```java
package lab.hadoop.sort;

public enum DelayCounters {
	not_available_arrival,
	scheduled_arrival,
	early_arrival,
	not_available_departure,
	scheduled_departure,
	early_departure;
}

```



6. GroupKeyComparator



```
package lab.hadoop.sort;

import org.apache.hadoop.io.WritableComparable;
import org.apache.hadoop.io.WritableComparator;

public class GroupKeyComparator extends WritableComparator {
	
	protected GroupKeyComparator() {
		super(DateKey.class,true);
	}


	
	@SuppressWarnings("rawtypes")
	@Override
	public int compare(WritableComparable w1, WritableComparable w2) {
		
	DateKey k1 = (DateKey) w1;
	DateKey k2 = (DateKey) w2;
	
	//연도값 비교
	return k1.getYear().compareTo(k2.getYear());
	
	}
	
}

```







7. GroupKeyPartitioner



```java
package lab.hadoop.sort;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapreduce.Partitioner;

public class GroupKeyPartitioner 
	extends Partitioner<DateKey, IntWritable> {
	
	@Override
	public int getPartition(DateKey key, IntWritable val, int numPartitions) {
		int hash = key.getYear().hashCode();
		int partition = hash % numPartitions;
		return partition;
	}
}

```





8. 메인 (드라이버)



```java
package lab.hadoop.sort;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;


public class DelayCountWithDateKey extends Configured implements Tool {
	
	public int run(String[] args) throws Exception {
		String[] otherArgs = new GenericOptionsParser(getConf(), args)
				.getRemainingArgs();
		
		//
		if(otherArgs.length != 2) {
			System.err.println("Usage: DelayCountWithDateKey <in> <out>");
			System.exit(2);
		}
		//
		Job job = new Job(getConf(), "DelayCountWithDateKey");
		
		
		//
		FileSystem hdfs = FileSystem.get(getConf());
		
		Path path = new Path(args[1]);
		if (hdfs.exists(path)) {
			hdfs.delete(path,true);
		}
		
		FileInputFormat.addInputPath(job, new Path(otherArgs[0]));//입력 패스 지정
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));//출력 패스 지정
		
		// Job 클래스 설정
		job.setJarByClass(DelayCountWithDateKey.class);//메인 클래스 지정
		job.setPartitionerClass(GroupKeyPartitioner.class);
		job.setGroupingComparatorClass(GroupKeyComparator.class);
		job.setSortComparatorClass(DateKeyComparator.class);
		
		//Mapper 클래스 설정
		job.setMapperClass(DelayCountMapperWithDateKey.class);//메퍼 클래스 지정
		job.setReducerClass(DelayCountReducerWithDateKey.class);//리듀서 클래스 지정
		
		job.setMapOutputKeyClass(DateKey.class);
		job.setMapOutputValueClass(IntWritable.class);
		
		//입출력 데이터 포맷 설정
		job.setInputFormatClass(TextInputFormat.class);//입력 포맷지정
		job.setOutputFormatClass(TextOutputFormat.class);//출력 포맷 지정
		
		//출력키 및 출력값 유형 설정
		job.setOutputKeyClass(DateKey.class);//출력 키의 타입(단어는 텍스트)
		job.setOutputValueClass(IntWritable.class);//출력 값의 타입(갯수는 정수)

		//MultipleOutputs 설정
		MultipleOutputs.addNamedOutput(job, "departure", 
				TextOutputFormat.class, DateKey.class, IntWritable.class);
		
		MultipleOutputs.addNamedOutput(job, "arrival", 
				TextOutputFormat.class, DateKey.class, IntWritable.class);
		
		
		job.waitForCompletion(true);//작업 실행 종료때까지 기다립니다.
		return 0;
	}
	
	public static void main(String[] args) throws Exception {
		int res = ToolRunner.run(new Configuration(),
				new DelayCountWithDateKey(), args);
		System.out.println("## RESULT:" + res);

	}

	
}


```





출력결과 



출국

![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190819/images/sort1.PNG>)



도착

![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190819/images/sort2.PNG>)



DelayCounters의 항목들

![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190819/images/sort3.PNG>)



part는 출력이 되지 않는다.

![1564104618052](<https://github.com/Q3333/ITL/blob/master/BigData/Hadoop/190819/images/sort4.PNG>)







hadoop fs -mkdir /output/delaycount

hadoop jar ./delaycount.jar -D workType=arrival /data/airline  /output/delaycount
#############분석자가 군집수를 설정(자르기)##################
#stats::cutree(계층형 군집분석결과, k=군집수)
library(stats)
library(cluster)
idist<-dist(iris[1:4])
hc<-hclust(idist)  # 계층형 군집분석
plot(hc, hang=-1)
rect.hclust(hc, k=4,  border="red")

#군집분석 결과를 대상으로 3개의 군집수를 지정 
ghc <- cutree(hc, k=3)
ghc   #군집을 의미하는 1~3의 숫자로 출력

iris$ghc <- ghc
table(iris$ghc)   # 군집수의 빈도수

#각 군집별로 내적 특성, 다른 군집과의 차이에 해당하는 외적 특성 확인
g1<-subset(iris, ghc==1)
summary(g1[1:4])

g2<-subset(iris, ghc==2)
summary(g2[1:4])

g3<-subset(iris, ghc==3)
summary(g3[1:4])


#############군집분석 : 최단연결법(Single Linkage Method)##########
군집에 속하는 두 개체(데이터) 사이의 최단 거리를 이용
가장 유사성이 큰 개체들을 군집으로 묶어 나가는 방법
빠르고, 자료에 대한 단조변환에 대하여 Tree구조가 불변하기 때문에 
순서적 의미를 갖는 자료에 대해서 좋은 결과를 제공함
최단연결법(Single Linkage Method)은 고립된 군집을 찾는데 유용

a<-c(1, 5)
b<-c(2, 3)
c<-c(5, 7)
d<-c(3, 5)
e<-c(5, 2)
data <- data.frame(a, b, c,d, e)
data
data<-t(data)
data
m1<-hclust(dist(data)^2, method="single")
plot(m1)


#### 최장연결법(Complete Linkage Method)###
군집들의 응집성을 찾는데 유용

m2<-hclust(dist(data)^2, method="complete")
plot(m2)


######## 와드연결법(Ward's  Method)#######
새로운 군집으로 인하여 파생되는 ESS(오차 제곱의 합)의 증가량을
 두 군집 사이의 거리로 정의하여 가장 유사성이 큰 개체들을 군집으로 묶어 가는 방법

m3<-hclust(dist(data)^2, method="ward.D2")
plot(m3)

#########평균 연결법(Average Linkage Method) #########
두 군집 사이의 거리를 각 군집에 속하는 모든 개체들의 평균거리로 정의하여
가장 유사성이 큰 개체들을 군집으로 묶어 가는 방법

m4<-hclust(dist(data)^2, method="average")
plot(m4)


##############비계층적 군집 분석 #######################
library(ggplot2)
data(diamonds)
t <- sample(1:nrow(diamonds), 1000)
test <- diamonds[t, ]   #표본으로 검정 데이터 생성
names(test)

data<- test[c("price", "carat", "depth", "table")]
head(data)

#계층적 군집분석
result <- hclust(dist(data), method="ave")
result
plot(result, hang=-1)

#3개의 군집수를 적용하여 비계층적 군집분석 수행
result2 <- kmeans(data, 3)  
names(result2)
result2$cluster #각 개체가 속하는 군집수 확인

data$cluster <- result2$cluster

#price에 가장 큰 영향을 주는 변수들 확인
cor(data[, -5], method="pearson")
plot(data[, -5])  #변수간의 상관계수 보기


library(corrgram)  #상관계수를 색상으로 시각화
corrgram(data[, -5], upper.panle=panel.conf) #상관계수 수치 추가

#비계층분석 결과 price에 가장 영향을 주는 ..군집수 2의 시각화
plot(data$carat, data$price, col=data#cluster)
#중심점 추가
points(result2$centers[, c("carat", "price")], col=c(3,1,2),
        pch=8, cex=5)
 


############ iris 데이터셋 비계층적 군집 분석 ##############
data<-iris
data$Species <- NULL
head(data)
m<-kmeans(data, 3)
m

table(iris$Species, m$cluster)
plot(data[c("Sepal.Length", "Sepal.Width")], main="kmeans", col=m$cluster)


m2<-kmeans(data, 4)
m2

table(iris$Species, m2$cluster)
plot(data[c("Sepal.Length", "Sepal.Width")], main="kmeans", col=m2$cluster)




#############트랜잭션 객체를 대상으로 연관규칙 생성##############
#arules::read.transactions(), apriori()
install.packages("arules")
library(arules)
tran <- read.transactions("./data/tran.txt", format="basket",sep=",")
#거래 data는 6개
inspect(tran)   #항목(품목) 확인

rule <- apriori(tran, parameter=list(supp=0.3, conf=0.1))  #규칙 16
#맥주를 구매한 사람은 대체로 고기를 사지 않는다
#{라면, 맥주} => {우유}는 향상도가 1.2이므로 두 상품간의 상관성이 높습니다.
rule2 <- apriori(tran, parameter=list(supp=0.1, conf=0.1))  #규칙 32

stran <- read.transactions("./data/demo_single", format="single", cols=c(1,2))
inspect(stran)


stran2 <- read.transactions("./data/single_format.csv", format="single", sep=",", cols=c(1,2), rm.duplicates=T)
stran2      #트랜잭션 248, 항목은 68
summary(stran2)

#규칙 생성 (연관규칙 생성을 위한 평가척도 기본값 supp=0.1, conf=0.8)
astran2 <- apriori(stran2)   # 102 rules

#규칙 확인
inspect(astran2)

#상위 5개만 향상도 기준 내림차순 
inspect(head(sort(astran2, by="lift" ), 5))


##### 연관규칙 생성, 네트워크 형태로 시각화######
data(Adult) 
str(Adult)   #성인 대상 인구 소득에 관한 설문 조사 데이터
# AdultUCI 데이터셋을 트랜잭션 객체로 변환한 데이터셋
# transaction  48,842 , item 는 115 
# 종속변수(Class)에 의해서 연간 개입 수입이 $5만 이상인지를 예측하는 데이터 셋
  
attributes(Adult)  # transaction의 변수와 범주
names(AdultUCI) #15개의 변수(컬럼)명

adult <- as(Adult, "data.frame") 
head(adult)
str(adult)
summary(adult)

ar <- apriori(Adult, parameter=list(supp=0.1, conf=0.8))  #rules는 6,137개

ar2 <- apriori(Adult, parameter=list(supp=0.3, conf=0.95))  #rules는 124개


ar3 <- apriori(Adult, parameter=list(supp=0.35, conf=0.95))  #rules는  67

ar4 <- apriori(Adult, parameter=list(supp=0.4, conf=0.95))  #rules는  36

#상위 6개 규칙
inspect(head(ar4))

#신뢰도 기준 내림차순 정렬 상위 6개
inspect(head(sort(ar4, descreasing=T, by="confidence")))


#향상도 기준 내림차순 정렬 상위 6개
inspect(head(sort(ar4, descreasing=T, by="lift")))


install.packages("arulesViz")
library(arulesViz)

plot(ar3, method="graph", control=list(type="items"))
# 5만 달러 이상의 연봉 수령자와 관련된 연관어 :


plot(ar4, method="graph", control=list(type="items"))
# 5만 달러 이상의 연봉 수령자와 관련된 연관어 :  
주당근무시간 형태는 full-time
인종은 백인
국가는 미국
자본손실 무
직업은 자영업
나이는 중년
교육수준 ...
결혼여부 기혼

###############Groceries 데이터 셋 연관분석################
data("Groceries")
str(Groceries)
Groceries
#1개월동안 실제 로컬 식품점 매장에서 판매되는 트랜잭션 데이터
#transaction은 9835, item은 169
Groceries_df <- as(Groceries, "data.frame")

rules <- apriori(Groceries, parameter= list(supp=0.001 , conf=0.8))  # rules 410
inspect(rules)
plot(rules, method="grouped")
#빈도수가 가장 높은 상품 순서대로 2개

rules2 <- apriori(Groceries, parameter= list(supp=0.002 , conf=0.8))  # rules 11
inspect(rules2)
plot(rules2, method="grouped")

#빈도수가 가장 높은 상품

규칙이 A상품 ->B상품 형태로 표현 : 왼쪽에 있는 LHS표현, 오른쪽 RHS 표현된다

#최대 길이(LHS와 RHS길이의 합) 3 이하 규칙 생성
rules <- apriori(Groceries, parameter= list(supp=0.001 , conf=0.8 , maxlen=3))  # rules  29
inspect(rules)

rules <- sort(rules, descreasing=T, by="confidence")
inspect(rules)
plot(rules, method="graph", control=list(type="items"))


######특정 상품 서브셋 생성하여 시각화하기######
wmilk <- subset(rules, rhs %in% 'whole milk')
wmilk 
inspect(wmilk)
plot(wmilk, method="graph")
 
aveg <- subset(rules, rhs %in% 'other vegetables')
aveg
inspect(aveg)
plot(aveg, method="graph")


################장바구니 연관분석 연습문제 1 ################
연관성 규칙은 상품 호은 서비스 간의 관계를 살펴보고 이로부터 유용한 규칙을 찾아내고자 할 때 이용될 수 있는 기법이다.
데이터들의 빈도수와 동시발생 확률을 이용하여 한 항목들의 그룹과 다른 항목들의 그룹 사이에 강한 연관성이 있음을 밝혀주는 기법이다.

예제 데이터 : B 마트에서 판매된 트랜잭션 데이터 파일
mybasket.csv

변수 : 의류, 냉동식품, 주류, 야채, 제과, 육류, 과자, 생활장식, 우유

분석문제 :
1. 전체 트랜잭션 개수와 상품아이템 유형은 몇개인가?   #transaction:786, item:10

2. 가장  발생빈도가 높은 상품아이템은 무엇인가?  #의류
3. 지지도를 10%로 설정했을 때의 생성되는 규칙의 가짓수는?  #rules: 127
4. 상품 아이템 중에서 가장 발생확률이 높은 아이템과 낮은 아이템은 무엇인가?  #의류, 밀크
5. 가장 발생가능성이 높은 <2개 상품간>의 연관규칙은 무엇인가?  #의류, 제과
6. 가장 발생가능성이 높은 <2개 상품이상에서> <제 3의 상품으로>의 연관규칙은 무엇인가?   #장식, 냉동, 제과

result <- read.transactions("./data/mybasket.csv", format="basket", sep=",")
result
summary(result)
image(result)
as(result, "data.frame")
rules <- apriori(result, parameter=list(supp=0.1, conf=0.1))
inspect(rules)

library(arulesViz)
plot(rules)
plot(rules, method="grouped")  #lhs가로축 조건과 rhs세로축-결과로 구성한 메트릭스 그래프
plot(rules, method="graph", control=list(type="items"))
plot(rules, method="graph", interactive=TRUE , control=list(type="items"))
         

############## Twitter SNS 연관어 분석 단계 #######################
단계 1] Twitter 로그인  -  https://twitter.com
단계 2] Twitter 앱 만들기  - https://apps.twitter.com/ko
앱 이름, 앱에 대한 설명문 10자 이상 입력, 웹사이트는 운영중인 사이트나 블러그 등 주소 입력
페이지 아래 라이센스 동의
※ Request token URL, Authorize URL, Access token URL  (앱 인증 요청시 필요함)
 
단계 3] Twitter 앱 설정
단계 4] Twitter 앱 키와 접근 토큰 생성

단계 5] Twitter 앱에 관한 사용자의 권한 설정
단계 6] Twitter 앱 토큰 생성
※ Access Token과 Access Token Secret 생성


#######Twitter 앱 인증 
#twitteR 패키지 로딩 ? twitter 인증 관련 함수 제공
#ROAuth  패키지 로딩 ? OAuthFactory 객체 제공
#Base64enc 패키지 로딩 ? enc2utf8()  함수 제공
install.packages("twitteR")
install.packages("ROAuth")
install.packages("base64enc")
library(twitteR)
library(ROAuth)
library(base64enc)


#  Twitter 앱 요청 URL과 API 설정
# [Details] - 3개 url 변수 생성
reqURL <- "https://api.twitter.com/oauth/request_token"
authURL <- "https://api.twitter.com/oauth/authorize"
accessURL <- "https://api.twitter.com/oauth/access_token"

# [Keys and Access Tokens] - 4개 변수 : ##Site에서 받아온다.
apiKey <-  "bINvDLa0dsPbo2la8PiscuUqC" 
apiSecret <- "PKNHc2ls7cnuFPbD0eWYxqXi7QMK2WCucWjYLWShZMQPu77SNS" 
accessToken="632641860-hADhYcejnc2AlMFxFKy7E2BwLmsLsZGiMjaStMcm"
accessTokenSecret="D4m5xjaihndouW4FLg3LxVxBUitRmSjKJBephvmkRL8x5"

# Twitter 앱 인증 요청
twitCred <- OAuthFactory$new(
  consumerKey = apiKey, 
  consumerSecret = apiSecret,
  requestURL = reqURL,
  accessURL = accessURL, 
  authURL = authURL
)


# Twitter 앱 인증 수행
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package =  "RCurl")))
twitCred$handshake()

# Twitter 앱 인증을 위한 PIN 받기 => 연결된 웹 화면에서 PIN번호 받아오기
setup_twitter_oauth(apiKey, 
                    apiSecret,
                    accessToken,
                    accessTokenSecret)


# 함수 실행 -> 선택: 1(1: Yes)


##Twitter 앱에 접근하여 데이터 가져오기

# 단계 1 : 검색어 입력과 검색 결과 받기 
keyword <- enc2utf8("빅데이터") # UTF-8 인코딩 방식 지정 - base 패키지 
test <- searchTwitter(keyword, n=300) # twitteR 패키지 제공 
test
class(test) # [1] "list"

# 단계 2 :  list 자료구조를 vector 자료구조로 변경
test_vec <- vector() # vector 객체 생성 
n <- 1: length(test)

for(i in n){
  test_vec[i] <- test[[i]]$getText()
}
test_vec

# data type과 구조보기 
class(test_vec); str(test_vec)

#파일 저장 및 가져오기
write.csv(test_vec, "c:/Rwork/output/test.txt", quote = FALSE, row.names = FALSE)
test_txt <- file("C:/Rwork/output/test.txt")
twitter <- readLines(test_txt)
str(twitter)


## Twitter 검색 데이터 대상 연관어 분석

# 단계 1 : 한글 처리를 위한 패키지 설치
library(rJava) # 아래와 같은 Error 발생 시 Sys.setenv()함수로 java 경로 지정
library(KoNLP) # rJava 라이브러리가 필요함

# 단계 2 :  줄 단위 단어 추출
lword <- Map(extractNoun, twitter) 
length(lword) 
lword <- unique(lword) # 중복제거1(전체 대상)
length(lword) 
lword <- sapply(lword, unique) # 중복제거2(줄 단위 대상) 
length(lword) 
lword # 추출 단어 확인

# 단계 3 :  데이터 전처리
# (1) 길이가 2~4 사이의 단어 필터링 함수 정의
filter1 <- function(x){
  nchar(x) <= 4 && nchar(x) >= 2 && is.hangul(x)
}
# (2) Filter(f,x) -> filter1() 함수를 적용하여 x 벡터 단위 필터링 
filter2 <- function(x){
  Filter(filter1, x)
}

# (3) 줄 단어 대상 필터링
lword <- sapply(lword, filter2)
lword # 추출 단어 확인(길이 1개 단어 삭제됨)

#  트랜잭션 생성 : 연관분석을 위해서 단어를 트랜잭션으로 변환
library(arules) 
wordtran <- as(lword, "transactions") # lword에 중복데이터가 있으면 error발생
wordtran 
inspect(wordtran)  # 트랜잭션 내용 보기

# 단어 간 연관규칙 산출
tranrules <- apriori(wordtran, parameter=list(supp=0.09, conf=0.8))  # 54 rule(s)
inspect(tranrules) # 연관규칙 생성 결과(23개) 보기

# 연관어 시각화 
# (1) 데이터 구조 변경 : 연관규칙 결과 -> 행렬구조 변경(matrix 또는 data.frame) 
rules <- labels(tranrules, ruleSep=" ") # 연관규칙 레이블을 " "으로 구분하여 변경   
rules # 예) 59 {경영,마케팅}   => {자금} -> 59 "{경영,마케팅} {자금}"
class(rules)

rules <- sapply(rules, strsplit, " ",  USE.NAMES=F) 
rules
class(rules) 

# 행 단위로 묶어서 matrix로 반환
rulemat <- do.call("rbind", rules)
rulemat
class(rulemat)

# (2) 연관어 시각화를 위한 igraph 패키지 설치
library(igraph)   

# (3) edgelist보기 - 연관단어를 정점 형태의 목록 제공 
ruleg <- graph.edgelist(rulemat[c(1:54),], directed=F) 

# (4) edgelist 시각화
X11()
plot.igraph(ruleg, vertex.label=V(ruleg)$name,
            vertex.label.cex=1.0, vertex.label.color='black', 
            vertex.size=20, vertex.color='green', vertex.frame.color='blue')


##########비정상 시계열 자료를 정상성 시계열 자료 변환 ##########
data(AirPassengers)  #12년간 항공기 탑승 승객 수
head(AirPassengers)
str(AirPassengers)

#차분을 이용한 평균에 대한 정상화
par(mfrow=c(1,2))
ts.plot(AirPassengers)   #시계열 시각화
diff <- diff(AirPassengers)  #차분 수행
plot(diff)   #평균 정상화


#로그를 이용한 분산에 대한 정상화
par(mfrow=c(1,2))
plot(AirPassengers)
log <-diff(log(AirPassengers))  #로그 + 차분 
plot(log)


#############시계열 자료로부터 추세선 시각화 ##################
data(WWWusage)   #인터넷 사용시간을 분 단위로 측정 
str(WWWusage)    #측정치 : 100  , 자료구조 형태: 벡터

ts.plot(WWWusage, type="l", col="red")  #가로축 :t , 세로축:시계열 데이터 값

#다중 시계열 자료의 추세선 시각화
data(EuStockMarkets)  #유럽 주요 주식의 주가지수 일일 마감 가격  
str(EuStockMarkets)  #DAX:독일, SMI:스위스, CAC: 프랑스 , FISE:영국)
EuStock <- data.frame(EuStockMarkets);
X11()
plot(EuStock$DAX[1:1000], type="l", col="red")
plot(EuStock$DAX[1:1000],EuStock$SMI[1:1000], main="주가지수 추세선")


###########################고급 시각화########################
시각화 주요 패키지 : graphics, lattice, ggplot2, ggmap
이산변수 시각화 : barplot(), dotchart(), pie() 
연속변수 시각화 : boxplot(), hist(), plot()

lattice 패키지는 서로 상관있는 확률적 종속변수의 시각화에 사용
특정 변수가 갖는 범주별로 독립된 패널을 격차(lattice)처럼 배치하여 
여러 개의 변수에 대한 범주를 세부적으로 시각화해주는 도구를 제공

ggplot2 패키지는 기하학적 객체들(점, 선, 막대 등)에 미적특성(색상, 모양, 크기)을 적용하여 시각화하는 방법을제공


ggmap 패키지는 지도를 기반으로 위치, 영역, 시각과 공간에 따른 차이 및 변화를 다루는 공간시각화에 적합

####lattice 패키지#####
histogram()  
densityplot() 연속형변수 밀도 그래프
barchart() 
dotplot()  점그래프
xyplot()  교차그래프
equal.count() 데이터셋에 지정된 영역만큼 범주화
coplot() 조건 변수와 관련 조건 그래프 
cloud()  3차원 산점도


install.packages("lattice")
library(lattice)

install.packages("mlmRev")
library(mlmRev)
data(Chem97)
#학생 대상 화확 점수를 기록한 데이터 셋

str(Chem97)  # data.frame':  31022 obs. of  8 variables:
#gcsescore : gcse개인평균성적
#lea : 지방교육청
table(Chem97$score)

head(Chem97,30) # 앞쪽 30개 레코드 

#  히스토그램 
histogram( ~ gcsescore, data=Chem97) 
# gcsescore변수를 대상으로 백분율 적용 히스토그램

histogram # histogram(~x축 | 조건, dataframe)
table(Chem97$score) #  0  2  4   6  8  10 <- 빈도수
# score 변수를 조건으로 지정 
histogram(~gcsescore | score, data=Chem97) # score 단위 
histogram(~gcsescore | factor(score), data=Chem97) # score 요인 단위

#  밀도 그래프 
densityplot(~gcsescore | factor(score), data=Chem97, 
            groups = gender, plot.points=T, auto.key = T) 
# 밀도 점 : plot.points=F
# 범례: auto.key=T
# 성별 단위(그룹화)로 GCSE점수를 밀도로 플로팅   




################막대 그래프 ################

# 1) 데이터셋 가져오기
data(VADeaths)  #사망연령대, 도시출신, 남녀
VADeaths
str(VADeaths)

# 2) 데이터셋 구조보기
mode(VADeaths) # numeric
class(VADeaths) # matrix

# 3) 데이터 리모델링
# (1) matrix -> data.frame 변환
df <- as.data.frame(VADeaths)
str(df) # 'data.frame':	5 obs. of  4 variables:
class(df) # "data.frame"
df 

# (2) matrix -> data.table 변환
dft <- as.data.frame.table(VADeaths)
str(dft) # 'data.frame':  20 obs. of  3 variables:
class(dft) # "data.frame"
dft # Var1  Var2 Freq -> 1열 기준으로 data.table 생성

# 막대 그래프 그리기  (x축은 사망비율, y축은 사망 연령대, 시골출신 , 도시출신)
barchart(Var1 ~ Freq | Var2, data=dft, layout=c(4,1))
# Var2변수 단위(그룹화)로 x축-Freq, y축-Var1으로 막대차트 플로팅

# 막대 그래프 그리기(origin 속성 사용)
barchart(Var1 ~ Freq | Var2, data=dft, layout=c(4,1), origin=0)


####################점 그래프 ############################
#dotplot(y축컬럼 ~x축 컬럼 | 조건, dataset , layout)

dotplot(Var1 ~ Freq | Var2 , dft) 

dotplot(Var1 ~ Freq | Var2 , dft, layout=c(4,1)) 

#Var2변수 단위로 그룹화하여 점을 연결하여 플로팅  
dotplot(Var1 ~ Freq, data=dft, groups=Var2, type="o", 
        auto.key=list(space="right", points=T, lines=T)) 


######################### 산점도 그래프 ####################
#xyplot(y축컬럼 ~x축 컬럼 | 조건변수, data=data.frame or list, layout)

library(datasets)
str(airquality) # datasets의 airqulity 테이터셋 로드

airquality # Ozone Solar.R Wind Temp Month(5~9) Day

# airquality의 Ozone(y),Wind(x) 산점도 플로팅
xyplot(Ozone ~ Wind, data=airquality) 
range(airquality$Ozone,na.rm=T)
xyplot(Ozone ~ Wind | Month, data=airquality) # 2행3컬럼 
xyplot(Ozone ~ Wind | factor(Month), data=airquality, layout=c(5,1))

# airquality 데이터셋의 Month 타입변경(factor)
convert <- transform(airquality, Month=factor(Month))
str(convert) # Month 변수의 Factor값 확인
# $ Month  : Factor w/ 5 levels "5","6","7","8"

convert # Ozone Solar.R Wind Temp Month Day
xyplot(Ozone ~ Wind | Month, data=convert, layout=c(5,1))
# 컬럼 제목 : Month 값으로 출력


#  quakes 데이터 셋으로 산점도 그래프 그리기 
head(quakes)
str(quakes) # 'data.frame':  1000 obs. of  5 variables:
#lat(위도), long(경도), depth(수심), mag(리히터 규모), stations(관측소)
range(quakes$stations)

# 지진발생 위치(위도와 경로) 
xyplot(lat~long, data=quakes, pch=".") 
# 그래프를 변수에 저장
tplot <- xyplot(lat~long, data=quakes, pch=".")
# 그래프에 제목 추가
tplot2<-update(tplot,
               main="1964년 이후 태평양에서 발생한 지진위치")
print(tplot2)


################# 산점도 그래프 그리기 ####################
# 1. depth 이산형 변수 범위 확인 
range(quakes$depth)# depth 범위

# 2. depth 변수 리코딩 : 6개의 범주(100단위)로 코딩 변경
quakes$depth2[quakes$depth >=40 & quakes$depth <=150] <- 1
quakes$depth2[quakes$depth >=151 & quakes$depth <=250] <- 2
quakes$depth2[quakes$depth >=251 & quakes$depth <=350] <- 3
quakes$depth2[quakes$depth >=351 & quakes$depth <=450] <- 4
quakes$depth2[quakes$depth >=451 & quakes$depth <=550] <- 5
quakes$depth2[quakes$depth >=551 & quakes$depth <=680] <- 6

# 3. 리코딩 변수(depth2)를 조건으로 산점도 그래프 그리기
convert <- transform(quakes, depth2=factor(depth2))
xyplot(lat~long | depth2, data=convert)


# 동일한 패널에 2개의 y축에 값을 표현
xyplot(Ozone + Solar.R ~ Wind | factor(Month), data=airquality,
       col=c("blue","red"),layout=c(5,1))



 


################# equal.count() 함수 이용 이산형 변수 범주화 
#################
# equal.count(data, number=n, overlang=0)

# (1) 1~150을 대상으로 겹치지 않게 4개 영역으로 범주화
numgroup<- equal.count(1:150, number=4, overlap=0)
numgroup

# (2) 지진의 깊이를 5개 영역으로 범주화
depthgroup<-equal.count(quakes$depth, number=5, overlap=0)
depthgroup

#범주화된 변수(depthgroup)를 조건으로 산점도 그래프 그리기 
xyplot(lat ~ long | depthgroup, data=quakes,
       main="Fiji Earthquakes(depthgruop)",
       ylab="latitude", xlab="longitude", pch="@",col='red' )

#수심과 리히터규모 변수를 동시에 적용하여 산점도 그래프 그리기 
magnitudegroup<-equal.count(quakes$mag, number=2, overlap=0)
magnitudegroup

# magnitudegroup변수 기준으로 플로팅
xyplot(lat ~ long | magnitudegroup, data=quakes,
       main="Fiji Earthquakes(magjitude)",
       ylab="latitude", xlab="longitude", pch="@", col='blue')


# 수심과 리히터 규모를 동시에 표현(2행 5열 패널 구조)
xyplot(lat ~ long | depthgroup*magnitudegroup, data=quakes,
       main="Fiji Earthquakes",
       ylab="latitude", xlab="longitude",
       pch="@",col=c("red","blue"))


# 이산형 변수로 리코딩한 뒤에 factor 형으로 변환하여 산점도 그래프 그리기 
quakes$depth3[quakes$depth >= 39.5 & quakes$depth <= 80.5] <- 'd1' 
quakes$depth3[quakes$depth >= 79.5 & quakes$depth <= 186.5] <- 'd2' 
quakes$depth3[quakes$depth >= 185.5 & quakes$depth <= 397.5] <- 'd3' 
quakes$depth3[quakes$depth >= 396.5 & quakes$depth <= 562.5] <- 'd4' 
quakes$depth3[quakes$depth >= 562.5 & quakes$depth <= 680.5] <- 'd5'

quakes$mag3[quakes$mag >= 3.95 & quakes$mag <= 4.65] <- 'm1' 
quakes$mag3[quakes$mag >= 4.55 & quakes$mag <= 6.45] <- 'm2'

convert <- transform(quakes, depth3=factor(depth3), mag3=factor(mag3))

xyplot(lat ~ long | depth3*mag3, data=convert, 
                    main="Fiji Earthquakes", ylab="latitude", 
                    xlab="longitude", pch="@", col=c("red", "blue"))


################# 조건 그래프 #################
coplot(lat~long | depth, data=quakes) # 2행3열, 0.5, 사이간격 6
coplot(lat~long | depth, data=quakes, overlap=0.1) # 겹치는 구간 : 0.1
coplot(lat~long | depth, data=quakes, number=5, row=1) # 사이간격 5, 1행 5열

#  패널과 조건 막대에 색 적용 후 조건 그래프 그리기 
coplot(lat~long | depth, data=quakes, number=5, row=1, panel=panel.smooth)
coplot(lat~long | depth, data=quakes, number=5, row=1, 
       col='blue',bar.bg=c(num='green')) # 패널과 조건 막대 색 


#   3차원 산점도 그래프 

#   위도, 경도, 깊이를 이용하여 3차원 산점도 그래프 그리기 
cloud(depth ~ lat * long , data=quakes,
      zlim=rev(range(quakes$depth)), 
      xlab="경도", ylab="위도", zlab="깊이")

#   테두리와 회전 속성을 추가하여 3차원 산점도 그래프 그리기 
cloud(depth ~ lat * long , data=quakes,
      zlim=rev(range(quakes$depth)), 
      panel.aspect=0.9,
      screen=list(z=45,x=-25),
      xlab="경도", ylab="위도", zlab="깊이")



####지도 공간 기법 시각화 : Google Static Maps API 이용 ####
geocode() : 거리주소 또는 장소 이름을 이용하여 지도 정보(위도, 경도) 얻을 수 있음 
get_googlemap() : 구글 지도서비스 API에 접근하여 정적 지도 다운로드 지원과 지도에 마커(maker)등을 삽입하고 자신이 원하는 줌 레벨과 중심점을 지정하여 지도 정보 생성
get_map() : 지도 서비스 관련 서버(GoogleMaps, OpenStreetMap, StamenMapsor, Naver Map)에 관련된 질의어를 지능형으로 인식하여 지도 정보 생성
get_navermap() : 네이버 지도서비스 API에 접근하여 정적 지도 다운로드 지원
ggimage() : ggplot2 패키지의 이미지와 동등한 수준으로 지도 이미지 생성
ggmap() 과 ggmapplot() : get_map()에 의해서 생성된 픽셀 객체를 지도 이미지로 시각화
qmap() : ggmap()과 get_map() 통합 기능
qmplot() : ggplot2 패키지의 qplot()과 동등한 수준으로 빠르게 지도 이미지 시각화


#get_googlemap(center, zoom, size, scale, format, maptype, language, sensor, color, markers, path)
#get_map(location, zoom, scale, maptype, source, color, language, api_key)


###########  Google Static Maps API 이용 ###############
remove.packages("ggmap")
remove.packages("tibble")
#install.packages('devtools')
library('devtools')
install_github('dkahle/ggmap', ref="tidyup")
library('ggmap')

#구글에 로그인하여 https://cloud.google.com/maps-platform/#get-started 에 접속 

register_google(key='발급받은키') # 부여받은 키 등록
names <- c("용두암","성산일출봉","정방폭포",
            "중문관광단지","한라산1100고지","차귀도")
addr <- c("제주시 용두암길 15",
           "서귀포시 성산읍 성산리",
           "서귀포시 동홍동 299-3",
           "서귀포시 중문동 2624-1",
           "서귀포시 색달동 산1-2",
           "제주시 한경면 고산리 125")
gc <- geocode(enc2utf8(addr))
 
# 지도위치정보 가져오기
gc <- geocode("seoul")
center <- as.numeric(gc)
center # 위도,경도

# 지도 정보 생성하기
map <- get_googlemap(center = center, language="ko-KR", color = "bw", scale = 2 )

# 지도 이미지 그리기
ggmap(map, extent = 'device')

# 지도 위에 marker 삽입하기 
df <- round(data.frame(x=jitter(rep(-95.36, 25), amount=.3), 
              y=jitter(rep(29.76, 25), amount=.3) ), digits=2)

map <- get_googlemap('houston', markers=df, path=df, scale=2)

ggmap(map, extent = 'device')



###############종합지도 서비스 관련 API 이용  

# roadmap 타입으로 지도 그리기
map <- get_map(location ="london", zoom=14, maptype='roadmap', scale=2)
# get_map("중심지역", 확대비율, 지도유형) : ggmap에서 제공하는 함수 
ggmap(map, size=c(600,600), extent='device')

# watercolor 타입으로 지도 그리기
map <- get_map(location ="seoul", zoom=8, maptype='watercolor', scale=2)
ggmap(map, size=c(600,600), extent='device')




######## 지도 이미지에 레이어 적용  

# 서울지역 4년제 대학교 위치 표시 
university <- read.csv("./data/university.csv",header=T)
university # # 학교명","LAT","LON"

# 레이어1 : 정적 지도 생성 
kor <- get_map('seoul', zoom = 11, maptype = 'watercolor')
ggmap(kor)

# 레이어2 : 지도위에 포인트 추가 
ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)
kor.map <- ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)

# 레이어3 : 지도위에 텍스트 추가
kor.map + geom_text(data=university, aes(x=LON+0.01, y=LAT+0.01,label=학교명),size=5)


# 지도 저장하기
ggsave("./otuput/university1.png",width=10.24,height=7.68)
# 밀도 적용 파일 저장
ggsave("./otuput/university2.png",dpi=1000) # 9.21 x 7.68 in image


 














